{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04480de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715a7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes an array with test accuracies for each class\n",
    "\n",
    "def stdevCheck(test_accuracies):\n",
    "    \n",
    "    mean = np.mean(test_accuracies)\n",
    "    stdev = np.std(test_accuracies)\n",
    "    \n",
    "    for i in range(len(test_accuracies)):\n",
    "        if ((test_accuracies[i] > mean + 3*stdev) or (test_accuracies[i] < mean - 3*stdev)):\n",
    "            # If a class is outside two standard deviations from the mean, return true\n",
    "            return True\n",
    "        \n",
    "    # If no classes are outside two standard deviations from the mean, return false\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09013c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes an array with test accuracies for each class\n",
    "\n",
    "def variationCheck(test_accuracies):\n",
    "    \n",
    "    worst_accuracy = min(test_accuracies)\n",
    "    best_accuracy = max(test_accuracies)\n",
    "    \n",
    "    threshold = 30 # To be tuned later\n",
    "    \n",
    "    if (best_accuracy - worst_accuracy > threshold):\n",
    "        # If the difference between the best and worst class accuracies is greater than 15%, return true\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        # If the difference between the best and worst class accuracies is not greater than 15%, return false\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360127d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes arrays with the train and test accuracies for each class\n",
    "\n",
    "def gapCheck(train_accuracies, test_accuracies):\n",
    "    \n",
    "    threshold = 45 # To be tuned later\n",
    "    \n",
    "    # Ensure that arrays are the same length\n",
    "    if (len(train_accuracies) == len(test_accuracies)): \n",
    "        \n",
    "        # Calculate train - test gap for each class\n",
    "        class_gaps = [train_accuracies[i] - test_accuracies[i] for i in range(len(train_accuracies))]\n",
    "        \n",
    "        for j in range(len(class_gaps)):\n",
    "            if abs(class_gaps[j]) > threshold:\n",
    "                # If a difference between train and test accuracy for a class is above threshold, return true\n",
    "                return True\n",
    "        \n",
    "        # If no class gap is greater than threshold, return false\n",
    "        return False\n",
    "    \n",
    "    else: \n",
    "        print(\"Error: training accuracy and test accuracy arrays are not the same length!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec6547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples from training\n",
    "train_acc = [99.68, 99.85, 99.82, 99.35, 99.66, 99.42, 99.68, 98.97, 99.16, 100]\n",
    "test_acc = [35.52, 48.23, 35.12, 35.18, 36.22, 29.70, 46.57, 34.98, 27.27, 31.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3c2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False because standard deviation is very large (12%)\n",
    "stdevCheck(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4080c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False because gap is 21% between best and worst accuracy\n",
    "variationCheck(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd0a8103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True because there is a substantial gap between training and testing accuracy (50-60%)\n",
    "gapCheck(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb9f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libby's examples - 0.1 train and 0.1 test\n",
    "\n",
    "trainacc0_1 = np.array([[99.6, 100.0, 99.9, 99.8, 99.68, 99.57, 99.71, 100.0, 99.58, 99.59], [99.9, 99.91, 99.69, 99.51, 99.46, 99.41, 99.60, 99.90, 99.40, 99.39], [99.69, 99.73, 99.60, 99.71, 99.08, 99.67, 100.0, 99.60, 98.83, 99.19], [99.46, 99.91, 99.61, 99.90, 99.69, 99.33, 99.79, 99.71, 99.30, 99.39]])\n",
    "\n",
    "testacc0_1 = np.array([[79.35, 79.34, 64.52, 70.97, 71.28, 69.62, 83.50, 75.96, 60.0, 68.97], [80.68, 83.67, 53.93, 70.43, 67.89, 67.06, 83.18, 70.10, 56.73, 64.29], [71.95, 71.88, 71.43, 67.59, 73.33, 62.37, 78.57, 72.64, 46.24, 68.91], [71.88, 93.58, 62.86, 67.89, 80.0, 62.24, 77.42, 71.00, 57.78, 69.47]])\n",
    "\n",
    "trainacc0_1_average = trainacc0_1.mean(axis = 0)\n",
    "testacc0_1_average = testacc0_1.mean(axis = 0)\n",
    "\n",
    "# Libby's examples - 0.9 train and 0.9 test\n",
    "\n",
    "trainacc0_9 = np.array([[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 99.89949748743719, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]])\n",
    "\n",
    "testacc0_9 = np.array([[94.56521739130434, 94.69026548672566, 97.97979797979798, 98.14814814814815, 100.0, 95.45454545454545, 100.0, 100.0, 97.89473684210526, 99.00990099009901], [97.24770642201835, 97.36842105263158, 96.84210526315789, 94.56521739130434, 97.9381443298969, 97.9381443298969, 97.67441860465117, 100.0, 100.0, 100.0], [96.42857142857143, 96.36363636363636, 96.875, 97.9381443298969, 99.02912621359224, 96.66666666666667, 96.15384615384616, 97.97979797979798, 97.67441860465117, 97.84946236559139], [92.78350515463917, 97.47899159663865, 98.0, 95.0, 97.84946236559139, 97.19626168224299, 97.16981132075472, 96.62921348314607, 100.0, 100.0]])\n",
    "\n",
    "trainacc0_9_average = trainacc0_9.mean(axis = 0)\n",
    "testacc0_9_average = testacc0_9.mean(axis = 0)\n",
    "\n",
    "# Libby's examples - 0.1 train and test on test set\n",
    "\n",
    "trainacc0_1_test= np.array([[99.59432048681542, 99.91063449508489, 100.0, 99.39148073022312, 99.36908517350157, 99.22737306843267, 99.89722507708119, 99.80824544582934, 99.79959919839679, 99.59308240081384], [99.09456740442656, 99.53789279112755, 99.49647532729104, 99.5136186770428, 99.38461538461539, 99.00881057268722, 99.89868287740629, 99.60591133004927, 98.96157840083073, 99.60591133004927], [99.70414201183432, 100.0, 99.9001996007984, 99.39271255060729, 99.5987963891675, 99.35553168635876, 100.0, 99.80119284294234, 99.2964824120603, 99.58246346555323], [99.79166666666667, 99.91197183098592, 99.70588235294117, 99.52651515151516, 99.56756756756756, 99.42196531791907, 99.79879275653923, 99.80601357904946, 99.19273461150352, 99.28716904276986]])\n",
    "\n",
    "testacc0_1_test = np.array([[72.52747252747253, 90.08264462809917, 77.45098039215686, 65.26315789473684, 72.63157894736842, 69.04761904761905, 81.11111111111111, 77.11864406779661, 69.0721649484536, 71.02803738317758], [72.34042553191489, 83.62068965517241, 72.22222222222223, 78.84615384615384, 71.56862745098039, 59.57446808510638, 82.55813953488372, 73.7864077669903, 62.37623762376238, 67.3913043478261], [71.76470588235294, 88.49557522123894, 68.26923076923077, 81.13207547169812, 82.4074074074074, 77.21518987341773, 81.31868131868131, 73.07692307692308, 64.81481481481481, 65.68627450980392], [83.50515463917526, 86.06557377049181, 79.0, 75.22123893805309, 76.59574468085107, 69.0909090909091, 81.52173913043478, 77.10843373493977, 56.12244897959184, 65.93406593406593]])\n",
    "\n",
    "trainacc0_1_test_average = trainacc0_1_test.mean(axis = 0)\n",
    "testacc0_1_test_average = testacc0_1_test.mean(axis = 0)\n",
    "\n",
    "# Libby's examples - 0.9 train and test on test set\n",
    "\n",
    "trainacc0_9_test = np.array([[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0], [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]])\n",
    "\n",
    "testacc0_9_test = np.array([[19.54022988505747, 15.0, 12.037037037037036, 16.037735849056602, 19.51219512195122, 14.606741573033707, 20.952380952380953, 18.103448275862068, 15.74074074074074, 13.924050632911392], [13.25301204819277, 14.40677966101695, 6.896551724137931, 13.043478260869565, 16.50485436893204, 9.090909090909092, 24.175824175824175, 26.605504587155963, 17.346938775510203, 10.784313725490197], [11.578947368421053, 13.675213675213675, 15.88785046728972, 11.627906976744185, 11.403508771929825, 18.39080459770115, 26.881720430107528, 18.181818181818183, 19.753086419753085, 11.818181818181818], [24.46808510638298, 10.56910569105691, 12.121212121212121, 16.853932584269664, 15.238095238095237, 12.631578947368421, 14.953271028037383, 24.50980392156863, 16.49484536082474, 17.97752808988764]])\n",
    "\n",
    "trainacc0_9_test_average = trainacc0_9_test.mean(axis = 0)\n",
    "testacc0_9_test_average = testacc0_9_test.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ba0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_results = [stdevCheck(testacc0_1_average), variationCheck(testacc0_1_average), gapCheck(trainacc0_1_average, testacc0_1_average)]\n",
    "model_0_9_results = [stdevCheck(testacc0_9_average), variationCheck(testacc0_9_average), gapCheck(trainacc0_9_average, testacc0_9_average)]\n",
    "model_0_1_test_results = [stdevCheck(testacc0_1_test_average), variationCheck(testacc0_1_test_average), gapCheck(trainacc0_1_test_average, testacc0_1_test_average)]\n",
    "model_0_9_test_results = [stdevCheck(testacc0_9_test_average), variationCheck(testacc0_9_test_average), gapCheck(trainacc0_9_test_average, testacc0_9_test_average)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47c89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[False, False, False],\n",
       " [False, False, False],\n",
       " [False, False, False],\n",
       " [False, False, True]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled = [model_0_1_results, model_0_9_results, model_0_1_test_results, model_0_9_test_results]\n",
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ba45b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now showing individual results for the four 0.1 train and 0.1 test models:\n",
      "[False, False, False]\n",
      "[False, False, True]\n",
      "[False, True, True]\n",
      "[False, True, False]\n",
      "Now showing individual results for the four 0.9 train and 0.9 test models:\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "Now showing individual results for the four 0.1 train and test on test set models:\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "[False, False, False]\n",
      "Now showing individual results for the four 0.9 train and test on test set models:\n",
      "[False, False, True]\n",
      "[False, False, True]\n",
      "[False, False, True]\n",
      "[False, False, True]\n"
     ]
    }
   ],
   "source": [
    "allModelNames = [\"0.1 train and 0.1 test\", \"0.9 train and 0.9 test\", \"0.1 train and test on test set\", \"0.9 train and test on test set\"]\n",
    "allModelResults = [[trainacc0_1, testacc0_1], [trainacc0_9, testacc0_9], [trainacc0_1_test, testacc0_1_test], [trainacc0_9_test, testacc0_9_test]]\n",
    "\n",
    "for i in range(0,4):\n",
    "    print(f\"Now showing individual results for the four {allModelNames[i]} models:\")\n",
    "    \n",
    "    groupTrainResult = allModelResults[i][0]\n",
    "    groupTestResult = allModelResults[i][1]\n",
    "    \n",
    "    for j in range(0,4):\n",
    "        individualTrainResult = groupTrainResult[j]\n",
    "        individualTestResult = groupTestResult[j]\n",
    "        \n",
    "        individualResults = [stdevCheck(individualTestResult), variationCheck(individualTestResult), gapCheck(individualTrainResult, individualTestResult)]\n",
    "        \n",
    "        print(individualResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487763f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
